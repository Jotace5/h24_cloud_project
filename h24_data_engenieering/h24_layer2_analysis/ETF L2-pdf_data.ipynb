{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 -Sampling of PDF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 archivos copiados a C:\\Users\\HP\\My Drive\\Inteligencia Artificial\\PROJECTS\\ML Ops - House24 - Form Recognizer\\ETF Layer2 - Pdf_datset\\Training Dataset\\metadata_sample\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "def sample_files(directory_path, sample_size=100, destination_folder=\"metadata_sample\"):\n",
    "    \"\"\"\n",
    "    Takes a random sample of files from a directory and copies them to a destination folder.\n",
    "    \"\"\"\n",
    "    # Get a list of all files in the directory\n",
    "    all_files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "    \n",
    "    # Check if there are enough files\n",
    "    if len(all_files) < sample_size:\n",
    "        print(f\"Error: The directory only has {len(all_files)} files, but {sample_size} were requested.\")\n",
    "        return\n",
    "    \n",
    "    # Take a random sample\n",
    "    sampled_files = random.sample(all_files, sample_size)\n",
    "\n",
    "    # Create the destination directory if it doesn't exist\n",
    "    dest_path = os.path.join(directory_path, destination_folder)\n",
    "    if not os.path.exists(dest_path):\n",
    "        os.makedirs(dest_path)\n",
    "\n",
    "    # Copy the sampled files to the destination directory\n",
    "    for file in sampled_files:\n",
    "        shutil.copy2(os.path.join(directory_path, file), dest_path)\n",
    "\n",
    "    print(f\"{sample_size} files copied to {dest_path}\")\n",
    "\n",
    "# Specify the directory\n",
    "directory = r\"C:\\Users\\HP\\My Drive\\Inteligencia Artificial\\PROJECTS\\ML Ops - House24 - Form Recognizer\\ETF Layer2 - Pdf_datset\\Training Dataset\"\n",
    "sample_files(directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevant Fields for Training Process\n",
    "\n",
    "The following fields are identified as relevant for the training process:\n",
    "\n",
    "- **Name**: Document title\n",
    "- **Producer**: Software used to convert the document to PDF\n",
    "- **Creator**: Software used to create the document\n",
    "- **TotalPages**: Number of pages in the document\n",
    "- **FileSize**: Size of the document file\n",
    "- **Title**: Document title\n",
    "- **Author**: Document author\n",
    "- **Subject**: Document subject\n",
    "- **CreationDate**: Document creation date\n",
    "- **ModDate**: Document modification date\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Analysis of PDF Metadata\n",
    "\n",
    "Creation of a CSV file with the selected metadata and subsequent analysis of the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "route = pd.read_csv(r'C:\\Users\\HP\\My Drive\\Inteligencia Artificial\\PROJECTS\\ML Ops - House24 - Form Recognizer\\ETF Layer2 - Pdf_datset\\metadata_2.0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script extracts metadata from PDF files, including the file path, title, author, subject, creator, producer, creation date, and modification date. It saves this information to a CSV file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def extract_metadata(pdf_path):\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        metadata = reader.metadata\n",
    "    return metadata if metadata else {}\n",
    "\n",
    "def process_directory(directory_path, output_csv):\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['Filepath', 'Title', 'Author', 'Subject', 'Creator', 'Producer', 'CreationDate', 'ModDate']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for root, dirs, files in os.walk(directory_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".pdf\"):\n",
    "                    pdf_path = os.path.join(root, file)\n",
    "                    try:\n",
    "                        metadata = extract_metadata(pdf_path)\n",
    "                        writer.writerow({\n",
    "                            'Filepath': pdf_path,\n",
    "                            'Title': metadata.get('/Title', ''),\n",
    "                            'Author': metadata.get('/Author', ''),\n",
    "                            'Subject': metadata.get('/Subject', ''),\n",
    "                            'Creator': metadata.get('/Creator', ''),\n",
    "                            'Producer': metadata.get('/Producer', ''),\n",
    "                            'CreationDate': metadata.get('/CreationDate', ''),\n",
    "                            'ModDate': metadata.get('/ModDate', '')\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {pdf_path}: {e}\")\n",
    "\n",
    "directory = r\"C:\\Users\\HP\\My Drive\\Inteligencia Artificial\\PROJECTS\\ML Ops - House24 - Form Recognizer\\ETF Layer2 - Pdf_datset\\Training Dataset\"\n",
    "output_file = 'metadata_v1.0.csv'\n",
    "process_directory(directory, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata Analysis Script Revision\n",
    "\n",
    "The result obtained was not as expected. Therefore, a new script is modified and created for the analysis of metadata.\n",
    "\n",
    "An analysis of the CSV generated by the `process_directory()` script is performed to determine which files are relevant for the training process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Metadata from PDF Files\n",
    "\n",
    "The provided script is used to extract metadata from PDF files and store it in a CSV format. Here's an explanation of the script:\n",
    "\n",
    "1. **Importing Libraries**: The script imports necessary libraries including PyPDF2 for working with PDF files, os for file operations, and csv for CSV file handling.\n",
    "\n",
    "2. **Defining Functions**:\n",
    "    - `extract_metadata(pdf_path)`: This function takes the path of a PDF file as input and extracts metadata such as producer, creator, total number of pages, etc. It utilizes PyPDF2 library to read the PDF file and extract metadata.\n",
    "    - `process_directory(directory_path, output_csv)`: This function processes all PDF files in the specified directory. It iterates through each PDF file, extracts metadata using the `extract_metadata()` function, calculates the file size, and writes the metadata to a CSV file specified by `output_csv`.\n",
    "\n",
    "3. **Processing PDF Files**:\n",
    "    - The script iterates through the directory specified by `directory_path`.\n",
    "    - For each PDF file found in the directory, it calls the `extract_metadata()` function to extract metadata.\n",
    "    - The metadata is then written to a CSV file specified by `output_csv`.\n",
    "\n",
    "4. **Handling Exceptions**:\n",
    "    - The script includes exception handling to catch any errors that may occur during the metadata extraction process. If an error occurs, it prints an error message along with the file path.\n",
    "\n",
    "5. **Usage**:\n",
    "    - Specify the directory containing the PDF files in the `directory` variable.\n",
    "    - Specify the name of the output CSV file in the `output_file` variable.\n",
    "    - Call the `process_directory()` function with the directory path and output CSV file name as arguments.\n",
    "\n",
    "This script is useful for extracting metadata from PDF files in a specified directory and storing it in a structured format for further analysis or processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def extract_metadata(pdf_path):\n",
    "    with open(pdf_path, 'rb') as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        metadata = reader.metadata\n",
    "        total_pages = len(reader.pages)\n",
    "    return {**metadata, 'TotalPages': total_pages} if metadata else {'TotalPages': total_pages}\n",
    "\n",
    "def process_directory(directory_path, output_csv):\n",
    "    with open(output_csv, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['Name', 'Producer', 'Creator', 'TotalPages', 'FileSize', 'Title', 'Author', 'Subject', 'CreationDate', 'ModDate']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for root, dirs, files in os.walk(directory_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".pdf\"):\n",
    "                    pdf_path = os.path.join(root, file)\n",
    "                    try:\n",
    "                        metadata = extract_metadata(pdf_path)\n",
    "                        file_size = os.path.getsize(pdf_path)\n",
    "                        writer.writerow({\n",
    "                            'Name': file,\n",
    "                            'Producer': metadata.get('/Producer', ''),\n",
    "                            'Creator': metadata.get('/Creator', ''),\n",
    "                            'TotalPages': metadata.get('TotalPages', ''),\n",
    "                            'FileSize': file_size,\n",
    "                            'Title': metadata.get('/Title', ''),\n",
    "                            'Author': metadata.get('/Author', ''),\n",
    "                            'Subject': metadata.get('/Subject', ''),\n",
    "                            'CreationDate': metadata.get('/CreationDate', ''),\n",
    "                            'ModDate': metadata.get('/ModDate', '')\n",
    "                        })\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing {pdf_path}: {e}\")\n",
    "\n",
    "directory = r\"C:\\Users\\HP\\My Drive\\Inteligencia Artificial\\PROJECTS\\ML Ops - House24 - Form Recognizer\\ETF Layer2 - Pdf_datset\\Training Dataset\\metadata_sample\"\n",
    "output_file = 'metadata_2.0.csv'\n",
    "process_directory(directory, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining Relevant Metadata Fields\n",
    "\n",
    "Based on the extracted metadata from the PDF files, the following fields are determined to be relevant:\n",
    "\n",
    "- **Name**: Title of the document\n",
    "- **Producer**: Software used to convert the document to PDF\n",
    "- **Creator**: Software used to create the document\n",
    "- **TotalPages**: Number of pages in the document\n",
    "- **FileSize**: Size of the document file\n",
    "\n",
    "These fields provide essential information about the PDF documents, which can be useful for various analytical and processing tasks.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Data Analysis\n",
    "\n",
    "### General Data\n",
    "\n",
    "- **Total Files**: 9933.\n",
    "\n",
    "### 'Name' Column\n",
    "\n",
    "- **Unique Files**: 9933.\n",
    "- Each file has a unique name in the dataset, indicating no duplicates based on name.\n",
    "\n",
    "### 'Producer' Column\n",
    "\n",
    "- **Unique Producers**: 45.\n",
    "- **Primary Producer**: Samsung-M4580FX, which produced 6416 files.\n",
    "- **Missing Data**: There are 50 files with missing producer information.\n",
    "\n",
    "### 'Creator' Column\n",
    "\n",
    "- **Unique Creators**: 25.\n",
    "- **Primary Creator**: Created By SAMSUNG MFP, associated with 6425 files.\n",
    "- **Missing Data**: A significant amount, 3363 files have no creator information. This might require further investigation, as more than a third of the data lacks this information.\n",
    "\n",
    "### 'TotalPages' Column\n",
    "\n",
    "- **Average Pages**: Approximately 3.62 pages.\n",
    "- **Range**: Varies between 1 page and 27 pages.\n",
    "- Most files have between 2 and 4 pages.\n",
    "\n",
    "### 'FileSize' Column\n",
    "\n",
    "- **Average Size**: Approximately 1604.79 KB.\n",
    "- **Range**: From as small as 1.88 KB to 22536.08 KB.\n",
    "- Most files have a size between 856.74 KB and 1914.33 KB.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
